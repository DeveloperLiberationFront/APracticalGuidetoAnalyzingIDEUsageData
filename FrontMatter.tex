\begin{center}
\section*{Abstract}
\end{center}
Meant to increase productivity, modern Integrated Development Environments such as Eclipse and Visual Studio provide tools and capabilities to perform tasks such as navigating among classes and methods, continuous compilation, code refactoring, automated testing, and integrated debugging. 
Instrumenting the IDE to collect usage data gives researchers a greater level of detail on developers’' work than previously possible.  Usage data supports analysis of how developers spend their time, what activities might benefit from greater tool support, where developers have difficulty comprehending code, and whether they are following specific practices such as test-driven development.
With usage data, we expect to uncover more nuggets of how developers create mental models, how they investigate code, how they perform mini trial and error experiments, and what might release further productivity improvements for everyone.

\section{Introduction}
As software development evolved, Integrated Development Environments (IDEs) sprang up to aid the developer in managing the ever increasing complexity of software programs.  Meant to increase productivity, modern IDEs such as Eclipse and Visual Studio provide tools and capabilities to perform tasks such as navigating among classes and methods, continuous compilation, code refactoring, automated testing, and integrated debugging.  The breadth of development activities supported by the IDE makes collecting editor, command, and tool usage data valuable for analyzing developers' work patterns.  

Prior work in the RSSE book on Collecting and processing data for recommendation systems provides a description of tools, analysis methods, and important findings from developer usage data analysis.  The RSSE chapter is also a great introduction to prior research applying usage data to solve issues that challenge developers.  In this chapter, we will provide a practical how-to description for collecting and analyzing usage data from IDEs.  Each topic will provide practical guidance with how-to examples.  
%We also provide a role-based view of analysis describing what a software engineering researcher can do with the data, what a developer can do, and what toolsmiths can learn from the data.

Instrumenting the IDE to collect usage data gives researchers a greater level of detail on developers’' work than previously possible. Instrumenting the IDE involves extending the IDE within the provided API framework.  Eclipse and Visual Studio support a rich API framework allowing logging of many commands and actions  as they occur.  Tools used for research that instrument the Visual Studio IDE include Hackystat\cite{V:johnson2003beyond}, Blaze, and Codealike.  Tools that instrument the Eclipse IDE include Mylyn Monitor, CodingSpectator~\cite{VakilianETAL2012UseDisuseMisuse}, Hackystat\cite{V:johnson2003beyond}, and Zorro\cite{Kou2010Operational}.

Usage data supports analysis of how developers spend their time\cite{V:johnson2003beyond}, what activities might benefit from greater tool support \cite{V:MurphyHill2012How}, where developers have difficulty comprehending code \cite{Carter2010Are}, even whether they are following specific practices such as test-driven development\cite{Kou2010Operational}.  Combining usage data with additional data dimensions such as tasks or code change history, researchers can understand larger influences of low-level developer practices.  With these data we can answer questions such as the level of expertise developers have for an area of source code. \cite{Fritz2010Degreeofknowledge}
%%WBS: Does it bother anyone that the example of how well the developer knows the code is both a successful research outcome and a missing element?

There are limits, however, to what IDE usage data can tell us.  The missing elements include things like what the developer's mental model of the code is or how they intend to alter the code to suit new requirements.  The developers'' experience, design ideas, and constraints they keep in mind during an implementation activity are factors that we must obtain separately.  

Looking forward, usage data from development environments provides a platform for greater understanding of developer's low-level practices.  We expect to uncover more nuggets of how developers create mental models, how they investigate code, how they perform mini trial and error experiments, and what might release further productivity improvements for everyone.
