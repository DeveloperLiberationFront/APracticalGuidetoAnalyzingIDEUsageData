
\section{Usage Data Research Concepts}

\subsection{What Is Usage Data and Why Analyze It?}
\input{UsageDataResearchConcepts/WhatIsUsageData}

\subsection{Privacy Concerns}
\input{UsageDataResearchConcepts/PrivacyConcerns}

\subsection{Other Data sources}
\input{UsageDataResearchConcepts/OtherDataSources}


\section{How to Collect Data}
\label{SecHowToCollectData}

There are many options for collecting usage data from IDEs.   Existing tools can provide ready made solutions for commonly used IDEs and some support collecting data from additional sources.   If you want to study data collected in prevous projects you can use the Eclipse archive for UDC data available below.


Existing UDC data is available through the Eclipse foundation at this URL:
\url{http://archive.eclipse.org/projects/usagedata/}
%could provide more analysis, maybe even BigData


In this section we discuss details on how to use exisitng data collectors for Eclipse including Usage Data Collector, Mylyn Monitor, and Coding Spectator and provide a sample program to build your own data collector for Microsoft Visual Studio.  Before we get into details, here is an overview of some existing frameworks that may work for you.

\begin{itemize}

	\item Eclipse: Usage Data Collector (UDC) discussed in section \ref{EclipseUsageDataColector} collects commands executed in the environment and editors and views that are invoked.
	
	\item Eclipse: Mylyn Monitor described in section \ref{MylynMonitor} collects task oriented events and can be configured for saving data
	
	\item CodingSpectator %https://github.com/vazexqi/CodingSpectator
, discussed in section \ref{CodingSpectator} focuses on refactoring actions and the context in which they are taken.
	
	\item For Visual Studio, section \ref{buildItYourself} describes in detail how to build your own Visual Studio extension that collects all command events from the IDE.
	
	\item Hackystat provides a framework to collect usage data from many sources.  We do not discuss Hackystat here, hoever you can consult papers and the code website for it to collect more information. \cite{V:johnson2003beyond}, %https://code.google.com/p/hackystat/
	
	\item CodeAlike is a Visual Studio extension for personal analytics and research of usage data related to coding efficiency.  Currently CodeAlike is a proprietary tool whose developers seek to collaborate on usage data stuides.

\end{itemize}

%lstlisting settings for section 2
\lstset{language=Java,
captionpos=b,
tabsize=3,
frame=lines,
numbers=left,
numberstyle=\tiny,
numbersep=5pt,
breaklines=true,
showstringspaces=false,
basicstyle=\footnotesize,
emph={label}}

\subsection{Eclipse Usage Data Collector}
\label{EclipseUsageDataCollector}
\input{ToolsToCollectData/EclipseUDC}

\subsection{Mylyn and the Eclipse Mylyn Monitor} 
\label{MylynMonitor}
\input{ToolsToCollectData/mylyn}

\input{ToolsToCollectData/codingspectator}

\subsection{Instrumenting the IDE -- Building it Yourself for Visual Studio} 
\label{buildItYourself}
\input{ToolsToCollectData/BuildItYourselfInVisualStudio}

%TODO Wrapup



\section{How to Analyze Usage Data}

Thus far we have been focusing on concrete usage data collection frameworks and the specific data collected by these frameworks. When analyzing this data, or data from other collection frameworks, data analysis follows several predictable patterns, which we discuss in this section. However, we first discuss the nature of the collected data, especially whether it is anonymous, which dramatically effects how it is analyzed.

\subsection{Types of Data}

\input{AnalyzingUsageData/typesOfData}

\subsection{Usage Data Format}
\input{AnalyzingUsageData/usageDataFormat}

\subsection{Magnitude Analysis}
\input{AnalyzingUsageData/magnitude}

\subsection{Categorization Analysis}
\input{AnalyzingUsageData/category}

\subsection{Sequence Analysis}
\input{AnalyzingUsageData/sequence}


\subsection{State Model Analysis}
\input{AnalyzingUsageData/states}

\subsection{Research combining usage data with other sources}
\input{AnalyzingUsageData/Reasearch_combining_usage_data}


\section{Limits of What You Can Learn from Usage Data}\label{sec:limitations}

Collecting usage data is potentially a boon to research, and as we have
pointed out, has many interesting and impactful applications.
Nonetheless, there are limits to what you can learn as a researcher
from usage data.
In fact, our experience is that researchers (and practitioners) have 
high expectations about what they can learn from usage data, and those
expecations often come crashing down after significant effort implementing
and deploying a data collection sytem.
So before you begin your usage data collection and analysis, consider
the following two limitations of usage data.

\textbf{Rationale is Hard to Capture.}
Usage data tells you what a software developer did, but not
why she did it.
For example, if your usage data tells you that a developer used 
new refactoring tool for the first time, from a trace alone you cannot determine whether
(a) she learned about the tool for the first time, (b) she had used the tool before,
but before you started collecting data, or (c) her finger slipped and 
she pressed a hotkey by accident.
A researcher may be able to distinguish between these by collecting additional information,
like asking the developer just after she used the tool why she used it,
but it is impossible to definitively separate these based on the 
usage data alone.

\textbf{Usage Data Never Captures Everything.}
Researchers often want to capture ``everything,'' or at least 
everything that a developer does.
This is fundamentally impossible, and the reason we introduced the 
goal-question metric.
If you have a system that captures all key presses, you are still 
lacking information about mouse movements.
If you have a system that also captures mouse movements, you're still
missing the files that the developer is working with.
If your system captures also the files, you still lacking the 
histories of those files.
And so on.
Ultimately, usage data is all about fitness for purpose -- is the data
you are analyzing fit for the purpose of your research questions.

To avoid these limitations, we recommend not thinking about 
usage data collection abstractly, but thinking about it concretely before
you begin.
Invent an ideal usage data trace, and ask yourself:

\begin{itemize}
  \item Does the data support my hypothesis?
  \item Are there alternative hypotheses that the data would support?
  \item Can the data be feasibly generated?
\end{itemize}

\noindent
Answering these questions will help you determine whether you can sidestep
the limitations of collecting and analyzing usage data.

%\section{ Perspectives on Data Analysis}
%
%
%\begin{enumerate}
%\item Creating and communicating developer oriented feedback
%\begin{itemize}
%	\item
%	Identifying developer viewpoints of the data
%	\item
%	Designing a data visualization for developers. 
%	\item
%	Issues of privacy or sensitivity of data for developers
%\end{itemize}
%\item Tailoring usage data to provide value to toolsmiths
%\begin{itemize}
%	\item 
%	Tool usage data
%	\item 
%	Analyzing contextual data relevant to tool use such as prior actions or follow-on actions, 
%	\item 
%	Determining whether tool use was successful.
%\end{itemize}
%\item Research perspectives and opportunities
%\begin{itemize}
%	\item
%	Ideas to study IDE usage include debugging tasks, task oriented, navigation, reading
%	\item visualization using tools (e.g. Tableau)
%	\item Research patterns (data scope/scale, combining with other data (examples)
%\end{itemize}
%
%\end{enumerate}

\section{A Look Ahead}

If the last two decades could be labeled the era
of big data collection, 
the next two decades will surely be labeled as the 
era of smarter big data analysis.
Many questions still remain:
How do we balance data privacy and data richness?
What are the long term effects of developer monitoring?
How can we maximize the value of data collection
for as many researchers as possible, and reduce the 
strain on research participants?
Answering these questions will help our research
community advance in usage data collection and analysis.

Usage data, while now widely collected, still remains largely 
an untapped resource by practitioners and rearchers.
In this chapter, we have explained how to collect and 
anlayze usage data, which we hope will help you ``stand
on the shoulders of giants'' and increase the ease
with which you can collect and analyze your own usage data.